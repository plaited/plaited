{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plaited World Agent GRPO Training\n",
        "\n",
        "Train the world agent with Group Relative Policy Optimization (GRPO) using browser execution for reward computation.\n",
        "\n",
        "## Why Local?\n",
        "\n",
        "GRPO requires browser execution for reward computation. The model generates UI code, which is validated by:\n",
        "1. **Tier 1: Static analysis** - Fast pattern checks (free)\n",
        "2. **Tier 3: Browser execution** - Story tests in Playwright (ground truth)\n",
        "\n",
        "Colab doesn't provide browser access, so GRPO runs locally with Playwright.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "1. **Complete SFT/DPO training** on Colab first (see `plaited-world-agent-training.ipynb`)\n",
        "2. **Download trained model** from HuggingFace\n",
        "3. **Install dependencies**:\n",
        "\n",
        "```bash\n",
        "pip install unsloth trl datasets transformers torch\n",
        "bun install  # For Plaited workshop\n",
        "bunx playwright install chromium\n",
        "```\n",
        "\n",
        "## Environment Variables\n",
        "\n",
        "```bash\n",
        "export HF_TOKEN=\"your-token\"\n",
        "export HF_USERNAME=\"your-username\"\n",
        "export HF_MODEL_NAME=\"plaited-world-agent-lora\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 1: Load Environment and Model\n",
        "import os\n",
        "from unsloth import FastLanguageModel\n",
        "\n",
        "hf_token = os.environ.get('HF_TOKEN')\n",
        "hf_username = os.environ.get('HF_USERNAME', 'plaited')\n",
        "hf_model_name = os.environ.get('HF_MODEL_NAME', 'plaited-world-agent-lora')\n",
        "\n",
        "# Load the SFT/DPO trained model\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=f\"{hf_username}/{hf_model_name}\",\n",
        "    max_seq_length=2048,\n",
        "    dtype=None,\n",
        "    load_in_4bit=True,\n",
        "    token=hf_token,\n",
        ")\n",
        "\n",
        "print(f\"Loaded model: {hf_username}/{hf_model_name}\")\n",
        "print(f\"Parameters: {model.num_parameters():,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 2: Load Intent Dataset\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load trajectories but only use intents for GRPO\n",
        "# The model generates responses, browser validates\n",
        "dataset = load_dataset(\"json\", data_files=\"trajectories.jsonl\", split=\"train\")\n",
        "\n",
        "# Extract just the intents for GRPO\n",
        "intent_dataset = dataset.map(lambda x: {\n",
        "    \"prompt\": x[\"messages\"][1][\"content\"]  # User message with intent\n",
        "})\n",
        "\n",
        "print(f\"Loaded {len(intent_dataset)} intents for GRPO\")\n",
        "print(f\"Sample intent: {intent_dataset[0]['prompt'][:100]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 3: Static Analysis Integration\n",
        "import subprocess\n",
        "import json\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "def run_static_analysis(code: str) -> dict:\n",
        "    \"\"\"\n",
        "    Run Tier 1 static analysis via Bun.\n",
        "    \n",
        "    Returns:\n",
        "        {\"passed\": bool, \"checks\": [...], \"tier\": 1}\n",
        "    \"\"\"\n",
        "    # Write code to temp file\n",
        "    with tempfile.NamedTemporaryFile(mode='w', suffix='.tsx', delete=False) as f:\n",
        "        f.write(code)\n",
        "        temp_path = f.name\n",
        "    \n",
        "    try:\n",
        "        # Run static analysis script\n",
        "        result = subprocess.run(\n",
        "            [\"bun\", \"run\", \"-e\", f\"\"\"\n",
        "import {{ runStaticAnalysis }} from 'plaited/agent-next'\n",
        "const code = await Bun.file('{temp_path}').text()\n",
        "const result = runStaticAnalysis(code)\n",
        "console.log(JSON.stringify(result))\n",
        "            \"\"\"],\n",
        "            capture_output=True,\n",
        "            text=True,\n",
        "            timeout=10\n",
        "        )\n",
        "        \n",
        "        if result.returncode == 0:\n",
        "            return json.loads(result.stdout.strip())\n",
        "        else:\n",
        "            return {\"passed\": False, \"tier\": 1, \"checks\": [{\"name\": \"parse\", \"passed\": False, \"message\": result.stderr}]}\n",
        "    finally:\n",
        "        os.unlink(temp_path)\n",
        "\n",
        "# Test static analysis\n",
        "test_code = '<button aria-label=\"Test\">Click me</button>'\n",
        "result = run_static_analysis(test_code)\n",
        "print(f\"Static analysis test: {result}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4: Browser Reward Function\n",
        "import subprocess\n",
        "import json\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "def run_browser_test(code: str) -> dict:\n",
        "    \"\"\"\n",
        "    Run Tier 3 browser test via workshop CLI.\n",
        "    \n",
        "    Returns:\n",
        "        {\"passed\": bool, \"a11yPassed\": bool, \"totalAssertions\": int, \"passedAssertions\": int}\n",
        "    \"\"\"\n",
        "    # Write generated code to temp story file\n",
        "    with tempfile.NamedTemporaryFile(mode='w', suffix='.stories.tsx', delete=False) as f:\n",
        "        # Wrap code in story format\n",
        "        story_code = f\"\"\"\n",
        "import {{ story }} from 'plaited/testing'\n",
        "\n",
        "{code}\n",
        "\n",
        "export const Generated = story({{\n",
        "  template: () => GeneratedTemplate(),\n",
        "  intent: 'Generated for GRPO training',\n",
        "  play: async ({{ assert }}) => {{\n",
        "    await assert.a11y()\n",
        "  }}\n",
        "}})\n",
        "\"\"\"\n",
        "        f.write(story_code)\n",
        "        temp_path = f.name\n",
        "    \n",
        "    try:\n",
        "        # Run workshop test\n",
        "        result = subprocess.run(\n",
        "            [\"bun\", \"plaited\", \"test\", temp_path, \"--json\"],\n",
        "            capture_output=True,\n",
        "            text=True,\n",
        "            timeout=30\n",
        "        )\n",
        "        \n",
        "        if result.returncode == 0:\n",
        "            return json.loads(result.stdout)\n",
        "        else:\n",
        "            return {\n",
        "                \"passed\": False,\n",
        "                \"a11yPassed\": False,\n",
        "                \"totalAssertions\": 0,\n",
        "                \"passedAssertions\": 0,\n",
        "                \"error\": result.stderr\n",
        "            }\n",
        "    finally:\n",
        "        os.unlink(temp_path)\n",
        "\n",
        "print(\"Browser test function ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 5: GRPO Reward Function\n",
        "\n",
        "def compute_reward(intent: str, generation: str) -> float:\n",
        "    \"\"\"\n",
        "    Compute reward from tiered analysis.\n",
        "    \n",
        "    Reward breakdown:\n",
        "    - Tier 1 (Static): 0.0 if fail, continue if pass (fast rejection)\n",
        "    - Tier 3 (Browser): \n",
        "        - Story passed: +0.5\n",
        "        - A11y passed: +0.3\n",
        "        - Assertion ratio: +0.2 * (passed/total)\n",
        "    \n",
        "    Args:\n",
        "        intent: The user intent that prompted generation\n",
        "        generation: The model's generated code\n",
        "    \n",
        "    Returns:\n",
        "        Reward value between 0.0 and 1.0\n",
        "    \"\"\"\n",
        "    # Tier 1: Static analysis (fast rejection)\n",
        "    static_result = run_static_analysis(generation)\n",
        "    if not static_result.get(\"passed\", False):\n",
        "        return 0.0  # Fast rejection for invalid code\n",
        "    \n",
        "    # Tier 3: Browser test (ground truth)\n",
        "    browser_result = run_browser_test(generation)\n",
        "    \n",
        "    reward = 0.0\n",
        "    \n",
        "    # Story passed: +0.5\n",
        "    if browser_result.get(\"passed\", False):\n",
        "        reward += 0.5\n",
        "    \n",
        "    # A11y passed: +0.3\n",
        "    if browser_result.get(\"a11yPassed\", False):\n",
        "        reward += 0.3\n",
        "    \n",
        "    # Assertion ratio: +0.2 * ratio\n",
        "    total = browser_result.get(\"totalAssertions\", 0)\n",
        "    passed = browser_result.get(\"passedAssertions\", 0)\n",
        "    if total > 0:\n",
        "        reward += 0.2 * (passed / total)\n",
        "    \n",
        "    return reward\n",
        "\n",
        "print(\"Reward function ready\")\n",
        "print(\"Reward breakdown: Static(0.0 if fail) + Story(0.5) + A11y(0.3) + Assertions(0.2)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 6: Configure GRPO Training\n",
        "from trl import GRPOConfig, GRPOTrainer\n",
        "\n",
        "grpo_config = GRPOConfig(\n",
        "    output_dir=\"./grpo-output\",\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=8,\n",
        "    learning_rate=1e-6,  # Very low LR for GRPO\n",
        "    logging_steps=10,\n",
        "    save_steps=50,\n",
        "    fp16=True,\n",
        "    max_length=2048,\n",
        "    # GRPO specific\n",
        "    num_generations=4,  # Generate 4 candidates per intent\n",
        "    temperature=0.8,    # Higher temperature for diversity\n",
        ")\n",
        "\n",
        "grpo_trainer = GRPOTrainer(\n",
        "    model=model,\n",
        "    args=grpo_config,\n",
        "    train_dataset=intent_dataset,\n",
        "    reward_fn=compute_reward,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "print(\"GRPO Trainer configured\")\n",
        "print(f\"Generating {grpo_config.num_generations} candidates per intent\")\n",
        "print(f\"Temperature: {grpo_config.temperature}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 7: Train with GRPO\n",
        "print(\"Starting GRPO training...\")\n",
        "print(\"This will generate code and validate in browser for each intent.\")\n",
        "print(\"Progress is logged every 10 steps.\")\n",
        "print()\n",
        "\n",
        "grpo_trainer.train()\n",
        "\n",
        "print()\n",
        "print(\"GRPO training complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 8: Save and Push to Hub\n",
        "import os\n",
        "\n",
        "hf_token = os.environ.get('HF_TOKEN')\n",
        "hf_username = os.environ.get('HF_USERNAME', 'plaited')\n",
        "hf_model_name = os.environ.get('HF_MODEL_NAME', 'plaited-world-agent-lora')\n",
        "\n",
        "MODEL_NAME = f\"{hf_username}/{hf_model_name}-grpo\"\n",
        "\n",
        "# Save locally first\n",
        "model.save_pretrained(f\"./{hf_model_name}-grpo\")\n",
        "tokenizer.save_pretrained(f\"./{hf_model_name}-grpo\")\n",
        "print(f\"Saved locally to ./{hf_model_name}-grpo\")\n",
        "\n",
        "# Push to HuggingFace Hub\n",
        "model.push_to_hub(MODEL_NAME, token=hf_token)\n",
        "tokenizer.push_to_hub(MODEL_NAME, token=hf_token)\n",
        "\n",
        "print(f\"\\nModel pushed to: https://huggingface.co/{MODEL_NAME}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "1. **Deploy to HuggingFace Inference Endpoints** with vLLM\n",
        "2. **Connect from TypeScript**:\n",
        "\n",
        "```typescript\n",
        "import { InferenceClient } from '@huggingface/inference'\n",
        "import { useWorldAgent, createCoreTools } from 'plaited/agent'\n",
        "\n",
        "const client = new InferenceClient(process.env.HF_TOKEN)\n",
        "\n",
        "const trigger = await useWorldAgent({\n",
        "  tools: createCoreTools({ outputDir: './generated' }),\n",
        "  model: {\n",
        "    inference: async (intent, schemas) => {\n",
        "      const response = await client.chatCompletion({\n",
        "        model: 'your-username/plaited-world-agent-lora-grpo',\n",
        "        endpointUrl: 'https://xxx.endpoints.huggingface.cloud',\n",
        "        messages: [{ role: 'user', content: intent }],\n",
        "        tools: schemas.map(s => ({ type: 'function', function: s }))\n",
        "      })\n",
        "      return response.choices[0]?.message?.tool_calls ?? []\n",
        "    }\n",
        "  }\n",
        "})\n",
        "```\n",
        "\n",
        "## Troubleshooting\n",
        "\n",
        "### Browser Tests Failing\n",
        "- Ensure Playwright is installed: `bunx playwright install chromium`\n",
        "- Check workshop CLI works: `bun plaited test training/stories`\n",
        "\n",
        "### Out of Memory\n",
        "- Reduce `per_device_train_batch_size` to 1\n",
        "- Reduce `num_generations` to 2\n",
        "\n",
        "### Slow Training\n",
        "- GRPO is inherently slower due to browser validation\n",
        "- Consider running overnight for larger datasets"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
